{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fd3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0907957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import games #import the module here, so that it can be reloaded.\n",
    "importlib.reload(games)\n",
    "Game2 = games.Game2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6fcc1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork:\n",
    "    def __init__(self, model, exp_size):\n",
    "        self.epsilon = 1.0\n",
    "        self.gamma = 0.97\n",
    "        self.epsilin_down_factor = 0.995\n",
    "        \n",
    "        self.policy_network = model\n",
    "        self.target_network = keras.models.clone_model(self.policy_network)\n",
    "        self.target_network.set_weights(self.policy_network.get_weights())\n",
    "        self.policy_network.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "                                    loss=keras.losses.mean_squared_error)\n",
    "        \n",
    "        self.replay_buffer = deque(maxlen=exp_size)\n",
    "        \n",
    "        self.steps = 0\n",
    "        self.c = 3\n",
    "        self.win_episodes = []\n",
    "        self.consecutive_wins = 0\n",
    "        self.rewards_gained = 0\n",
    "        \n",
    "    \n",
    "    def get_action(self, state_input, action_list, random=True):\n",
    "        if not random:\n",
    "            action = np.argmax(self.policy_network.predict(state_input, verbose=0))\n",
    "        elif np.random.rand() > self.epsilon:\n",
    "            action = np.argmax(self.policy_network.predict(state_input, verbose=0))\n",
    "        else:\n",
    "            action = np.random.choice(action_list, 1).item()\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def action(self, state_input):\n",
    "        np.argmax(self.target_network.predict(state_input))\n",
    "    \n",
    "    \n",
    "    def train(self, batch_size, state_input, action, reward, next_state_input, done):\n",
    "        self.replay_buffer.append((state_input, action, reward, next_state_input, done))\n",
    "        \n",
    "        if batch_size >= len(self.replay_buffer):\n",
    "            return\n",
    "        else:\n",
    "            memories = random.sample(self.replay_buffer, batch_size)\n",
    "        states = np.squeeze(np.array([memory[0] for memory in memories]))\n",
    "        actions = np.array([memory[1] for memory in memories])\n",
    "        rewards = np.array([memory[2] for memory in memories])\n",
    "        next_states = np.squeeze(np.array([memory[3] for memory in memories]))\n",
    "        dones = np.array([memory[4] for memory in memories])\n",
    "        \n",
    "        q_values = self.policy_network.predict(states, verbose=0)\n",
    "        next_q_values = self.target_network.predict(next_states, verbose=0)\n",
    "        \n",
    "        targets = np.copy(q_values)\n",
    "        for i in range(batch_size):\n",
    "            targets[i, int(actions[i])] = rewards[i] + self.gamma * np.max(next_q_values[i]) * (1 - dones[i])\n",
    "        \n",
    "        self.policy_network.fit(states, targets, batch_size=32, epochs=1, verbose=0)\n",
    "        \n",
    "        self.steps += 1\n",
    "        if self.steps == self.c:\n",
    "            self.target_network.set_weights(self.policy_network.get_weights()) \n",
    "            self.steps = 0\n",
    "        \n",
    "        if reward > 0:\n",
    "            self.rewards_gained += 1\n",
    "            self.epsilon = max(0.1, self.epsilon * self.epsilin_down_factor)\n",
    "        \n",
    "        if done:\n",
    "            gain_perc = self.rewards_gained / 8\n",
    "            print(f'{gain_perc:0.5f}')\n",
    "            self.rewards_gained = 0\n",
    "            if gain_perc >= 0.7:\n",
    "                self.win_episodes.append(episode)\n",
    "                self.consecutive_wins += 1\n",
    "            elif gain_perc < 0.7:\n",
    "                self.consecutive_wins = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6bffc082",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 5, 5\n",
    "num_actions = 4\n",
    "action_list = np.array(range(num_actions))\n",
    "consecutive_wins_lmt = 5\n",
    "max_steps_replay = 5\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(x*y*max_steps_replay)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(4, activation='linear')\n",
    "    ]\n",
    ")\n",
    "agent = DeepQNetwork(model, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c8bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, wins: [], epsilon: 1.0\n",
      "episode: 1, wins: [], epsilon: 1.0\n",
      "episode: 2, wins: [], epsilon: 1.0\n",
      "episode: 3, wins: [], epsilon: 1.0\n",
      "episode: 4, wins: [], epsilon: 1.0\n",
      "episode: 5, wins: [], epsilon: 1.0\n",
      "episode: 6, wins: [], epsilon: 1.0\n",
      "episode: 7, wins: [], epsilon: 1.0\n",
      "episode: 8, wins: [], epsilon: 1.0\n",
      "episode: 9, wins: [], epsilon: 1.0\n",
      "episode: 10, wins: [], epsilon: 1.0\n",
      "episode: 11, wins: [], epsilon: 1.0\n",
      "episode: 12, wins: [], epsilon: 1.0\n",
      "episode: 13, wins: [], epsilon: 1.0\n",
      "episode: 14, wins: [], epsilon: 1.0\n",
      "episode: 15, wins: [], epsilon: 1.0\n",
      "episode: 16, wins: [], epsilon: 1.0\n",
      "episode: 17, wins: [], epsilon: 1.0\n",
      "episode: 18, wins: [], epsilon: 1.0\n",
      "episode: 19, wins: [], epsilon: 1.0\n",
      "episode: 20, wins: [], epsilon: 1.0\n",
      "episode: 21, wins: [], epsilon: 1.0\n",
      "episode: 22, wins: [], epsilon: 1.0\n",
      "episode: 23, wins: [], epsilon: 1.0\n",
      "episode: 24, wins: [], epsilon: 1.0\n",
      "episode: 25, wins: [], epsilon: 1.0\n",
      "episode: 26, wins: [], epsilon: 1.0\n",
      "episode: 27, wins: [], epsilon: 1.0\n",
      "episode: 28, wins: [], epsilon: 1.0\n",
      "episode: 29, wins: [], epsilon: 1.0\n",
      "episode: 30, wins: [], epsilon: 1.0\n",
      "episode: 31, wins: [], epsilon: 1.0\n",
      "episode: 32, wins: [], epsilon: 1.0\n",
      "episode: 33, wins: [], epsilon: 1.0\n",
      "episode: 34, wins: [], epsilon: 1.0\n",
      "episode: 35, wins: [], epsilon: 1.0\n",
      "episode: 36, wins: [], epsilon: 1.0\n",
      "episode: 37, wins: [], epsilon: 1.0\n",
      "episode: 38, wins: [], epsilon: 1.0\n",
      "episode: 39, wins: [], epsilon: 1.0\n",
      "episode: 40, wins: [], epsilon: 1.0\n",
      "episode: 41, wins: [], epsilon: 1.0\n",
      "episode: 42, wins: [], epsilon: 1.0\n",
      "episode: 43, wins: [], epsilon: 1.0\n",
      "episode: 44, wins: [], epsilon: 1.0\n",
      "episode: 45, wins: [], epsilon: 1.0\n",
      "episode: 46, wins: [], epsilon: 1.0\n",
      "episode: 47, wins: [], epsilon: 1.0\n",
      "episode: 48, wins: [], epsilon: 1.0\n",
      "episode: 49, wins: [], epsilon: 1.0\n",
      "episode: 50, wins: [], epsilon: 1.0\n",
      "episode: 51, wins: [], epsilon: 1.0\n",
      "episode: 52, wins: [], epsilon: 1.0\n",
      "episode: 53, wins: [], epsilon: 1.0\n",
      "0.00000\n",
      "episode: 54, wins: [], epsilon: 1.0\n",
      "0.12500\n",
      "episode: 55, wins: [], epsilon: 0.995\n",
      "0.25000\n",
      "episode: 56, wins: [], epsilon: 0.985074875\n",
      "0.50000\n",
      "episode: 57, wins: [], epsilon: 0.9655206468094844\n",
      "0.62500\n",
      "episode: 58, wins: [], epsilon: 0.9416228069143757\n",
      "0.00000\n",
      "episode: 59, wins: [], epsilon: 0.9416228069143757\n",
      "0.00000\n",
      "episode: 60, wins: [], epsilon: 0.9416228069143757\n",
      "0.37500\n",
      "episode: 61, wins: [], epsilon: 0.9275689688183278\n",
      "0.00000\n",
      "episode: 62, wins: [], epsilon: 0.9275689688183278\n",
      "0.00000\n",
      "episode: 63, wins: [], epsilon: 0.9275689688183278\n",
      "0.50000\n",
      "episode: 64, wins: [], epsilon: 0.9091562615825302\n",
      "0.00000\n",
      "episode: 65, wins: [], epsilon: 0.9091562615825302\n",
      "0.50000\n",
      "episode: 66, wins: [], epsilon: 0.8911090557802088\n",
      "0.12500\n",
      "episode: 67, wins: [], epsilon: 0.8866535105013078\n",
      "0.50000\n",
      "episode: 68, wins: [], epsilon: 0.8690529955452602\n",
      "0.00000\n",
      "episode: 69, wins: [], epsilon: 0.8690529955452602\n",
      "0.00000\n",
      "episode: 70, wins: [], epsilon: 0.8690529955452602\n",
      "0.37500\n",
      "episode: 71, wins: [], epsilon: 0.8560822709551227\n",
      "0.12500\n",
      "episode: 72, wins: [], epsilon: 0.851801859600347\n",
      "0.12500\n",
      "episode: 73, wins: [], epsilon: 0.8475428503023453\n",
      "0.00000\n",
      "episode: 74, wins: [], epsilon: 0.8475428503023453\n",
      "0.00000\n",
      "episode: 75, wins: [], epsilon: 0.8475428503023453\n",
      "0.25000\n",
      "episode: 76, wins: [], epsilon: 0.8390886103705794\n",
      "0.12500\n",
      "episode: 77, wins: [], epsilon: 0.8348931673187264\n",
      "0.12500\n",
      "episode: 78, wins: [], epsilon: 0.8307187014821328\n",
      "0.00000\n",
      "episode: 79, wins: [], epsilon: 0.8307187014821328\n",
      "0.00000\n",
      "episode: 80, wins: [], epsilon: 0.8307187014821328\n",
      "0.37500\n",
      "episode: 81, wins: [], epsilon: 0.8183201210226743\n",
      "0.12500\n",
      "episode: 82, wins: [], epsilon: 0.8142285204175609\n",
      "0.12500\n",
      "episode: 83, wins: [], epsilon: 0.810157377815473\n",
      "0.00000\n",
      "episode: 84, wins: [], epsilon: 0.810157377815473\n",
      "0.25000\n",
      "episode: 85, wins: [], epsilon: 0.8020760579717637\n",
      "0.37500\n",
      "episode: 86, wins: [], epsilon: 0.7901049725470279\n",
      "0.12500\n",
      "episode: 87, wins: [], epsilon: 0.7861544476842928\n",
      "0.12500\n",
      "episode: 88, wins: [], epsilon: 0.7822236754458713\n",
      "0.12500\n",
      "episode: 89, wins: [], epsilon: 0.778312557068642\n",
      "0.00000\n",
      "episode: 90, wins: [], epsilon: 0.778312557068642\n",
      "0.50000\n",
      "episode: 91, wins: [], epsilon: 0.7628626641409962\n",
      "0.50000\n",
      "episode: 92, wins: [], epsilon: 0.7477194593032545\n",
      "0.37500\n",
      "episode: 93, wins: [], epsilon: 0.736559652908221\n",
      "0.00000\n",
      "episode: 94, wins: [], epsilon: 0.736559652908221\n",
      "0.50000\n",
      "episode: 95, wins: [], epsilon: 0.7219385759785162\n",
      "0.37500\n",
      "episode: 96, wins: [], epsilon: 0.7111635524897149\n",
      "0.12500\n",
      "episode: 97, wins: [], epsilon: 0.7076077347272662\n",
      "0.50000\n",
      "episode: 98, wins: [], epsilon: 0.6935613678313175\n",
      "0.00000\n",
      "episode: 99, wins: [], epsilon: 0.6935613678313175\n",
      "0.62500\n",
      "episode: 100, wins: [], epsilon: 0.6763948591909945\n",
      "0.00000\n",
      "episode: 101, wins: [], epsilon: 0.6763948591909945\n",
      "0.37500\n",
      "episode: 102, wins: [], epsilon: 0.6662995813682115\n",
      "0.12500\n",
      "episode: 103, wins: [], epsilon: 0.6629680834613705\n",
      "0.37500\n",
      "episode: 104, wins: [], epsilon: 0.653073201944699\n",
      "0.62500\n",
      "episode: 105, wins: [], epsilon: 0.6369088258938781\n",
      "0.00000\n",
      "episode: 106, wins: [], epsilon: 0.6369088258938781\n",
      "0.00000\n",
      "episode: 107, wins: [], epsilon: 0.6369088258938781\n",
      "0.12500\n",
      "episode: 108, wins: [], epsilon: 0.6337242817644086\n",
      "0.00000\n",
      "episode: 109, wins: [], epsilon: 0.6337242817644086\n",
      "0.12500\n",
      "episode: 110, wins: [], epsilon: 0.6305556603555866\n",
      "0.00000\n",
      "episode: 111, wins: [], epsilon: 0.6305556603555866\n",
      "0.37500\n",
      "episode: 112, wins: [], epsilon: 0.6211445383053219\n",
      "0.00000\n",
      "episode: 113, wins: [], epsilon: 0.6211445383053219\n",
      "0.37500\n",
      "episode: 114, wins: [], epsilon: 0.6118738784280476\n",
      "0.37500\n",
      "episode: 115, wins: [], epsilon: 0.6027415843082742\n",
      "0.12500\n",
      "episode: 116, wins: [], epsilon: 0.5997278763867329\n",
      "0.25000\n",
      "episode: 117, wins: [], epsilon: 0.5937455908197752\n",
      "0.37500\n",
      "episode: 118, wins: [], epsilon: 0.5848838636585911\n",
      "0.37500\n",
      "episode: 119, wins: [], epsilon: 0.5761543988830038\n",
      "0.12500\n",
      "episode: 120, wins: [], epsilon: 0.5732736268885887\n",
      "0.37500\n",
      "episode: 121, wins: [], epsilon: 0.5647174463480732\n",
      "0.50000\n",
      "episode: 122, wins: [], epsilon: 0.5535075230322891\n",
      "0.12500\n",
      "episode: 123, wins: [], epsilon: 0.5507399854171277\n",
      "0.50000\n",
      "episode: 124, wins: [], epsilon: 0.5398075216808175\n",
      "0.00000\n",
      "episode: 125, wins: [], epsilon: 0.5398075216808175\n",
      "0.50000\n",
      "episode: 126, wins: [], epsilon: 0.5290920728090721\n",
      "0.12500\n",
      "episode: 127, wins: [], epsilon: 0.5264466124450268\n",
      "0.50000\n",
      "episode: 128, wins: [], epsilon: 0.5159963842937159\n",
      "0.25000\n",
      "episode: 129, wins: [], epsilon: 0.510849320360386\n",
      "0.00000\n",
      "episode: 130, wins: [], epsilon: 0.510849320360386\n",
      "0.12500\n",
      "episode: 131, wins: [], epsilon: 0.5082950737585841\n",
      "0.12500\n",
      "episode: 132, wins: [], epsilon: 0.5057535983897912\n",
      "0.25000\n",
      "episode: 133, wins: [], epsilon: 0.500708706245853\n",
      "0.75000\n",
      "episode: 134, wins: [133], epsilon: 0.4858739637363176\n",
      "0.00000\n",
      "episode: 135, wins: [133], epsilon: 0.4858739637363176\n",
      "0.50000\n",
      "episode: 136, wins: [133], epsilon: 0.47622912292284103\n",
      "0.12500\n",
      "episode: 137, wins: [133], epsilon: 0.4738479773082268\n",
      "0.00000\n",
      "episode: 138, wins: [133], epsilon: 0.4738479773082268\n",
      "0.00000\n",
      "episode: 139, wins: [133], epsilon: 0.4738479773082268\n",
      "0.25000\n",
      "episode: 140, wins: [133], epsilon: 0.46912134373457726\n",
      "0.25000\n",
      "episode: 141, wins: [133], epsilon: 0.46444185833082485\n",
      "0.75000\n",
      "episode: 142, wins: [133, 141], epsilon: 0.4506816115185697\n",
      "0.25000\n",
      "episode: 143, wins: [133, 141], epsilon: 0.446186062443672\n",
      "0.25000\n",
      "episode: 144, wins: [133, 141], epsilon: 0.4417353564707963\n",
      "0.37500\n",
      "episode: 145, wins: [133, 141], epsilon: 0.4351424010585501\n",
      "0.50000\n",
      "episode: 146, wins: [133, 141], epsilon: 0.42650460709830135\n",
      "0.37500\n",
      "episode: 147, wins: [133, 141], epsilon: 0.42013897252428334\n",
      "0.37500\n",
      "episode: 148, wins: [133, 141], epsilon: 0.41386834584198684\n",
      "0.37500\n",
      "episode: 149, wins: [133, 141], epsilon: 0.40769130904675194\n",
      "0.25000\n",
      "episode: 150, wins: [133, 141], epsilon: 0.4036245882390106\n",
      "0.00000\n",
      "episode: 151, wins: [133, 141], epsilon: 0.4036245882390106\n",
      "0.50000\n",
      "episode: 152, wins: [133, 141], epsilon: 0.39561243860243744\n",
      "0.37500\n",
      "episode: 153, wins: [133, 141], epsilon: 0.3897078735047413\n",
      "0.25000\n",
      "episode: 154, wins: [133, 141], epsilon: 0.3858205374665315\n",
      "0.37500\n",
      "episode: 155, wins: [133, 141], epsilon: 0.3800621177172763\n",
      "0.25000\n",
      "episode: 156, wins: [133, 141], epsilon: 0.37627099809304654\n",
      "0.25000\n",
      "episode: 157, wins: [133, 141], epsilon: 0.37251769488706843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00000\n",
      "episode: 158, wins: [133, 141], epsilon: 0.37251769488706843\n",
      "0.00000\n",
      "episode: 159, wins: [133, 141], epsilon: 0.37251769488706843\n",
      "0.25000\n",
      "episode: 160, wins: [133, 141], epsilon: 0.36880183088056995\n",
      "0.25000\n",
      "episode: 161, wins: [133, 141], epsilon: 0.36512303261753626\n",
      "0.00000\n",
      "episode: 162, wins: [133, 141], epsilon: 0.36512303261753626\n",
      "0.25000\n",
      "episode: 163, wins: [133, 141], epsilon: 0.3614809303671764\n",
      "0.12500\n",
      "episode: 164, wins: [133, 141], epsilon: 0.3596735257153405\n",
      "0.25000\n",
      "episode: 165, wins: [133, 141], epsilon: 0.35608578229633\n",
      "0.12500\n",
      "episode: 166, wins: [133, 141], epsilon: 0.3543053533848483\n",
      "0.12500\n",
      "episode: 167, wins: [133, 141], epsilon: 0.35253382661792404\n",
      "0.00000\n",
      "episode: 168, wins: [133, 141], epsilon: 0.35253382661792404\n",
      "0.25000\n",
      "episode: 169, wins: [133, 141], epsilon: 0.34901730169741024\n",
      "0.00000\n",
      "episode: 170, wins: [133, 141], epsilon: 0.34901730169741024\n",
      "0.00000\n",
      "episode: 171, wins: [133, 141], epsilon: 0.34901730169741024\n",
      "0.12500\n",
      "episode: 172, wins: [133, 141], epsilon: 0.3472722151889232\n",
      "0.00000\n",
      "episode: 173, wins: [133, 141], epsilon: 0.3472722151889232\n",
      "0.62500\n",
      "episode: 174, wins: [133, 141], epsilon: 0.3386767948568688\n",
      "0.25000\n",
      "episode: 175, wins: [133, 141], epsilon: 0.3352984938281715\n",
      "0.25000\n",
      "episode: 176, wins: [133, 141], epsilon: 0.33195389135223546\n",
      "0.25000\n",
      "episode: 177, wins: [133, 141], epsilon: 0.32864265128599696\n",
      "0.25000\n",
      "episode: 178, wins: [133, 141], epsilon: 0.3253644408394192\n",
      "0.00000\n",
      "episode: 179, wins: [133, 141], epsilon: 0.3253644408394192\n",
      "0.12500\n",
      "episode: 180, wins: [133, 141], epsilon: 0.3237376186352221\n",
      "0.25000\n",
      "episode: 181, wins: [133, 141], epsilon: 0.32050833588933575\n",
      "0.00000\n",
      "episode: 182, wins: [133, 141], epsilon: 0.32050833588933575\n",
      "0.00000\n",
      "episode: 183, wins: [133, 141], epsilon: 0.32050833588933575\n",
      "0.25000\n",
      "episode: 184, wins: [133, 141], epsilon: 0.3173112652388396\n",
      "0.25000\n",
      "episode: 185, wins: [133, 141], epsilon: 0.3141460853680822\n",
      "0.25000\n",
      "episode: 186, wins: [133, 141], epsilon: 0.31101247816653554\n",
      "0.25000\n",
      "episode: 187, wins: [133, 141], epsilon: 0.3079101286968243\n",
      "0.00000\n",
      "episode: 188, wins: [133, 141], epsilon: 0.3079101286968243\n",
      "0.25000\n",
      "episode: 189, wins: [133, 141], epsilon: 0.30483872516307353\n",
      "0.25000\n",
      "episode: 190, wins: [133, 141], epsilon: 0.3017979588795719\n",
      "0.25000\n",
      "episode: 191, wins: [133, 141], epsilon: 0.2987875242397482\n",
      "0.25000\n",
      "episode: 192, wins: [133, 141], epsilon: 0.29580711868545667\n",
      "0.12500\n",
      "episode: 193, wins: [133, 141], epsilon: 0.2943280830920294\n",
      "0.25000\n",
      "episode: 194, wins: [133, 141], epsilon: 0.2913921604631864\n",
      "0.00000\n",
      "episode: 195, wins: [133, 141], epsilon: 0.2913921604631864\n",
      "0.50000\n",
      "episode: 196, wins: [133, 141], epsilon: 0.285607880564032\n",
      "0.75000\n",
      "episode: 197, wins: [133, 141, 196], epsilon: 0.27714603575484437\n",
      "0.00000\n",
      "episode: 198, wins: [133, 141, 196], epsilon: 0.27714603575484437\n",
      "0.00000\n",
      "episode: 199, wins: [133, 141, 196], epsilon: 0.27714603575484437\n",
      "0.12500\n",
      "episode: 200, wins: [133, 141, 196], epsilon: 0.2757603055760701\n",
      "0.00000\n",
      "episode: 201, wins: [133, 141, 196], epsilon: 0.2757603055760701\n",
      "0.00000\n",
      "episode: 202, wins: [133, 141, 196], epsilon: 0.2757603055760701\n",
      "0.12500\n",
      "episode: 203, wins: [133, 141, 196], epsilon: 0.2743815040481898\n",
      "0.00000\n",
      "episode: 204, wins: [133, 141, 196], epsilon: 0.2743815040481898\n",
      "0.25000\n",
      "episode: 205, wins: [133, 141, 196], epsilon: 0.27164454854530906\n",
      "0.12500\n",
      "episode: 206, wins: [133, 141, 196], epsilon: 0.2702863258025825\n",
      "0.00000\n",
      "episode: 207, wins: [133, 141, 196], epsilon: 0.2702863258025825\n",
      "0.12500\n",
      "episode: 208, wins: [133, 141, 196], epsilon: 0.2689348941735696\n",
      "0.00000\n",
      "episode: 209, wins: [133, 141, 196], epsilon: 0.2689348941735696\n",
      "1.00000\n",
      "episode: 210, wins: [133, 141, 196, 209], epsilon: 0.2583638820072446\n",
      "0.25000\n",
      "episode: 211, wins: [133, 141, 196, 209], epsilon: 0.25578670228422234\n",
      "0.37500\n",
      "episode: 212, wins: [133, 141, 196, 209], epsilon: 0.2519690537792925\n",
      "0.12500\n",
      "episode: 213, wins: [133, 141, 196, 209], epsilon: 0.2507092085103961\n",
      "0.25000\n",
      "episode: 214, wins: [133, 141, 196, 209], epsilon: 0.24820838415550486\n",
      "0.25000\n",
      "episode: 215, wins: [133, 141, 196, 209], epsilon: 0.2457325055235537\n",
      "0.12500\n",
      "episode: 216, wins: [133, 141, 196, 209], epsilon: 0.24450384299593592\n",
      "0.00000\n",
      "episode: 217, wins: [133, 141, 196, 209], epsilon: 0.24450384299593592\n",
      "0.25000\n",
      "episode: 218, wins: [133, 141, 196, 209], epsilon: 0.24206491716205145\n",
      "0.00000\n",
      "episode: 219, wins: [133, 141, 196, 209], epsilon: 0.24206491716205145\n",
      "0.87500\n",
      "episode: 220, wins: [133, 141, 196, 209, 219], epsilon: 0.23371867538818816\n",
      "0.62500\n",
      "episode: 221, wins: [133, 141, 196, 209, 219], epsilon: 0.22793384675362674\n",
      "0.62500\n",
      "episode: 222, wins: [133, 141, 196, 209, 219], epsilon: 0.22229219984074702\n",
      "0.25000\n",
      "episode: 223, wins: [133, 141, 196, 209, 219], epsilon: 0.22007483514733558\n",
      "0.12500\n",
      "episode: 224, wins: [133, 141, 196, 209, 219], epsilon: 0.2189744609715989\n",
      "0.50000\n",
      "episode: 225, wins: [133, 141, 196, 209, 219], epsilon: 0.21462770857094118\n",
      "0.12500\n",
      "episode: 226, wins: [133, 141, 196, 209, 219], epsilon: 0.21355457002808648\n",
      "0.50000\n",
      "episode: 227, wins: [133, 141, 196, 209, 219], epsilon: 0.20931540516921554\n",
      "0.75000\n",
      "episode: 228, wins: [133, 141, 196, 209, 219, 227], epsilon: 0.2031139149609751\n",
      "0.00000\n",
      "episode: 229, wins: [133, 141, 196, 209, 219, 227], epsilon: 0.2031139149609751\n",
      "0.75000\n",
      "episode: 230, wins: [133, 141, 196, 209, 219, 227, 229], epsilon: 0.19709615934585656\n",
      "0.62500\n",
      "episode: 231, wins: [133, 141, 196, 209, 219, 227, 229], epsilon: 0.192217783647157\n",
      "0.50000\n",
      "episode: 232, wins: [133, 141, 196, 209, 219, 227, 229], epsilon: 0.18840216465300522\n",
      "0.00000\n",
      "episode: 233, wins: [133, 141, 196, 209, 219, 227, 229], epsilon: 0.18840216465300522\n",
      "0.87500\n",
      "episode: 234, wins: [133, 141, 196, 209, 219, 227, 229, 233], epsilon: 0.18190617987607657\n",
      "0.25000\n",
      "episode: 235, wins: [133, 141, 196, 209, 219, 227, 229, 233], epsilon: 0.1800916657318127\n",
      "0.50000\n",
      "episode: 236, wins: [133, 141, 196, 209, 219, 227, 229, 233], epsilon: 0.17651675623376062\n",
      "0.75000\n",
      "episode: 237, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236], epsilon: 0.1712870076899825\n",
      "0.25000\n",
      "episode: 238, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236], epsilon: 0.16957841978827493\n",
      "0.75000\n",
      "episode: 239, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.16455423674261854\n",
      "0.00000\n",
      "episode: 240, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.16455423674261854\n",
      "0.50000\n",
      "episode: 241, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.16128775296900558\n",
      "0.50000\n",
      "episode: 242, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.1580861105294992\n",
      "0.62500\n",
      "episode: 243, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.15417328217978102\n",
      "0.50000\n",
      "episode: 244, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.15111286553822956\n",
      "0.37500\n",
      "episode: 245, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.14885748713096328\n",
      "0.50000\n",
      "episode: 246, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.14590259167570602\n",
      "0.25000\n",
      "episode: 247, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.14444721332374086\n",
      "0.37500\n",
      "episode: 248, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.14229132060898236\n",
      "0.62500\n",
      "episode: 249, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238], epsilon: 0.138769433003975\n",
      "0.75000\n",
      "episode: 250, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.1346580429260134\n",
      "0.25000\n",
      "episode: 251, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.13331482894782642\n",
      "0.50000\n",
      "episode: 252, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.13066846301911936\n",
      "0.37500\n",
      "episode: 253, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.12871821987500112\n",
      "0.37500\n",
      "episode: 254, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.12679708435358925\n",
      "0.37500\n",
      "episode: 255, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.12490462201997637\n",
      "0.50000\n",
      "episode: 256, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.12242520289863423\n",
      "0.37500\n",
      "episode: 257, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.12059799144222175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50000\n",
      "episode: 258, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249], epsilon: 0.11820406108847166\n",
      "0.75000\n",
      "episode: 259, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258], epsilon: 0.11470197137452155\n",
      "0.62500\n",
      "episode: 260, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258], epsilon: 0.11186295456362313\n",
      "0.75000\n",
      "episode: 261, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260], epsilon: 0.1085487359239089\n",
      "1.00000\n",
      "episode: 262, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261], epsilon: 0.1042820154910064\n",
      "0.00000\n",
      "episode: 263, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261], epsilon: 0.1042820154910064\n",
      "0.00000\n",
      "episode: 264, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261], epsilon: 0.1042820154910064\n",
      "0.00000\n",
      "episode: 265, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261], epsilon: 0.1042820154910064\n",
      "0.00000\n",
      "episode: 266, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261], epsilon: 0.1042820154910064\n",
      "0.75000\n",
      "episode: 267, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266], epsilon: 0.10119240105273684\n",
      "0.50000\n",
      "episode: 268, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266], epsilon: 0.1\n",
      "0.50000\n",
      "episode: 269, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266], epsilon: 0.1\n",
      "0.50000\n",
      "episode: 270, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266], epsilon: 0.1\n",
      "0.87500\n",
      "episode: 271, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270], epsilon: 0.1\n",
      "0.75000\n",
      "episode: 272, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.50000\n",
      "episode: 273, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.62500\n",
      "episode: 274, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.12500\n",
      "episode: 275, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.25000\n",
      "episode: 276, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.50000\n",
      "episode: 277, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.00000\n",
      "episode: 278, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.37500\n",
      "episode: 279, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.25000\n",
      "episode: 280, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.25000\n",
      "episode: 281, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.62500\n",
      "episode: 282, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n",
      "0.25000\n",
      "episode: 283, wins: [133, 141, 196, 209, 219, 227, 229, 233, 236, 238, 249, 258, 260, 261, 266, 270, 271], epsilon: 0.1\n"
     ]
    }
   ],
   "source": [
    "# init_agent_pos = 13\n",
    "init_agent_pos = 15\n",
    "# init_rewards_pos = [3, 4, 8, 11, 22, 24, 17, 7]\n",
    "init_rewards_pos = [3, 2, 13, 11, 23, 24, 16, 0]\n",
    "init_holes_pos = []\n",
    "max_steps = 30\n",
    "env = Game2(x, y, init_agent_pos, init_rewards_pos, init_holes_pos, max_steps, max_steps_replay)\n",
    "\n",
    "agent.epsilon = 1.0\n",
    "agent.consecutive_wins = 0\n",
    "agent.win_episodes = []\n",
    "\n",
    "for episode in range(500):\n",
    "    print(f'episode: {episode}, wins: {agent.win_episodes}, epsilon: {agent.epsilon}')\n",
    "    observation, reward, done = env.reset()\n",
    "    while not done:\n",
    "#         state_input = observation.reshape(-1, x * y)\n",
    "        action = agent.get_action(observation, action_list)\n",
    "        next_observation, reward, done = env.step(action)\n",
    "#         next_state_input = next_observation.reshape(-1, x * y)\n",
    "        agent.train(256, observation, action, reward, next_observation, done)\n",
    "        observation = next_observation\n",
    "    if agent.consecutive_wins >= consecutive_wins_lmt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "631ce13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | |O|O|\n",
      "| | |O|O| |\n",
      "| | | | | |\n",
      "| | |O| | |\n",
      "| | |O| |O|\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# init_agent_pos = 15\n",
    "init_agent_pos = 13\n",
    "# init_rewards_pos = [3, 2, 13, 11, 23, 24, 16, 0]\n",
    "init_rewards_pos = [3, 4, 8, 11, 22, 24, 17, 7]\n",
    "init_holes_pos = []\n",
    "max_steps = 30\n",
    "env = Game2(x, y, init_agent_pos, init_rewards_pos, init_holes_pos, max_steps, max_steps_replay)\n",
    "observation, reward, terminated = env.reset()\n",
    "env.render()\n",
    "time.sleep(0.2)\n",
    "while not terminated:\n",
    "#     state_input = observation.reshape(-1, x * y)\n",
    "#     action = agent.get_action(state_input, action_list)\n",
    "    action = np.argmax(agent.policy_network.predict(observation))\n",
    "    next_observation, reward, terminated = env.step(action)\n",
    "    clear_output(wait=True)\n",
    "    env.render()\n",
    "    time.sleep(0.2)\n",
    "    observation = next_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75e8087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.replay_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba39e1d",
   "metadata": {},
   "source": [
    "# Game testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a38bb3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | |O|O|\n",
      "| | |O|O| |\n",
      "| |O| | | |\n",
      "| | |O| | |\n",
      "| | |O| |O|\n",
      "\r"
     ]
    }
   ],
   "source": [
    "init_agent_pos = 0\n",
    "init_rewards_pos = [3, 4, 8, 11, 22, 24, 17, 7]\n",
    "init_holes_pos = []\n",
    "max_steps = 30\n",
    "env = Game2(x, y, init_agent_pos, init_rewards_pos, init_holes_pos, max_steps, 3)\n",
    "observation, reward, terminated = env.reset()\n",
    "env.render()\n",
    "time.sleep(0.2)\n",
    "while not terminated:\n",
    "    action = random.randint(0, 3)\n",
    "    next_observation, reward, terminated = env.step(action)\n",
    "    clear_output(wait=True)\n",
    "    env.render()\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8a94061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | |O|O|\n",
      "| | |O|O| |\n",
      "| |Y| | | |\n",
      "| | |O| | |\n",
      "| | |O| |O|\n",
      "\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init_agent_pos = 0\n",
    "init_rewards_pos = [3, 4, 8, 11, 22, 24, 17, 7]\n",
    "init_holes_pos = []\n",
    "max_steps = 30\n",
    "env = Game2(x, y, init_agent_pos, init_rewards_pos, init_holes_pos, max_steps, 5)\n",
    "while True:\n",
    "    observation, reward, terminated = env.reset()\n",
    "    env.render()\n",
    "    time.sleep(0.2)\n",
    "    while not terminated:\n",
    "        action = random.randint(0, 3)\n",
    "        next_observation, reward, terminated = env.step(action)\n",
    "        clear_output(wait=True)\n",
    "        env.render()\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd1949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
